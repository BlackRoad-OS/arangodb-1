{"id":"armadillo-10","title":"Code cleanup and polish","description":"Final cleanup pass to improve code quality: introduce value objects, centralize magic constants, fix naming consistency, and verify performance.","design":"1. Introduce value objects (reduce primitive obsession):\n   - ServerId (string with validation)\n   - Port (integer with range validation)\n   - DeploymentId (string with validation)\n   - Replace primitive types with value objects\n   - Update type hints throughout\n   \n2. Centralize magic constants:\n   - Audit for hardcoded values (timeouts, ports, paths)\n   - Move to InfrastructureConfig or appropriate config\n   - Document rationale for each value\n   \n3. Fix naming consistency:\n   - Audit _private_method usage\n   - Ensure private methods aren't called externally\n   - Standardize public API naming conventions\n   - Remove any inconsistent patterns\n   \n4. Performance testing:\n   - Benchmark refactored code vs baseline\n   - Ensure no regressions\n   - Profile hot paths\n   - Document performance characteristics","acceptance_criteria":"- Value objects introduced for key types\n- All magic constants centralized in config\n- Naming conventions consistent\n- Performance benchmarks show no regressions\n- Documentation updated\n- All tests passing","notes":"Progress - Magic Constants Eliminated:\n✅ DeploymentOrchestrator: Now uses TimeoutConfig for all operations\n✅ InstanceManager: All public methods use config-based timeouts\n✅ Dynamic timeout calculation based on actual server count (not magic 4x multiplier)\n✅ Eliminated 15+ hardcoded timeout values in critical deployment paths\n\nResults:\n- All timeouts centralized in TimeoutConfig\n- Timeouts scale dynamically with deployment size\n- Better logging shows calculated timeouts\n- All 494 tests passing\n\nRemaining (from original plan):\n- Value objects (ServerId, Port, DeploymentId)\n- Naming consistency audit  \n- Performance benchmarking\n\nCurrent status: Targeted approach successful for timeouts (most impactful).\nDecision needed: Continue with value objects/naming or consider sufficient?","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-10-25T11:25:08.686707002+02:00","updated_at":"2025-10-26T11:28:50.62475364+01:00","closed_at":"2025-10-26T11:28:50.62475364+01:00"}
{"id":"armadillo-11","title":"Introduce ServerId value object to replace string primitives","description":"Replace string primitive for server_id with a proper value object to add type safety and validation.\n\nCurrently server_id is typed as `str` in ~27+ locations across instances/ module, leading to potential bugs where any string can be passed.\n\nA ServerId value object would:\n- Prevent empty/invalid server IDs\n- Make the domain model more explicit\n- Catch errors at construction time rather than runtime\n- Self-document the code","design":"1. Create armadillo/core/value_objects.py with ServerId class\n2. Update type hints in instances/server.py, manager.py, server_registry.py, deployment_planner.py (~27 locations total)\n3. Update factory methods to construct ServerId objects\n4. Update comparison logic: `server_id == \"foo\"` → `server_id.value == \"foo\"`\n5. Update all tests to use ServerId constructor\n\nImplementation notes:\n- ServerId validates non-empty alphanumeric identifiers\n- Implements __eq__, __hash__ for use in dicts/sets\n- Provides .value property for string access","acceptance_criteria":"- ServerId class implemented with validation\n- All type hints updated from `str` to `ServerId`\n- All construction sites create ServerId objects\n- All comparison logic updated\n- All tests passing\n- No string primitives used for server identifiers","status":"closed","priority":4,"issue_type":"chore","created_at":"2025-10-26T11:29:02.64005518+01:00","updated_at":"2025-11-03T13:49:32.075930099+01:00","closed_at":"2025-11-03T13:49:32.075930099+01:00"}
{"id":"armadillo-12","title":"Introduce Port value object to replace int primitives","description":"Replace integer primitive for ports with a proper value object to add validation and prevent invalid port numbers.\n\nCurrently port is typed as `int` in ~13+ locations, allowing any integer including invalid port numbers (\u003c 1024 or \u003e 65535).\n\nA Port value object would:\n- Enforce valid port range (1024-65535)\n- Prevent privileged ports (\u003c 1024) from being used accidentally\n- Make port allocation logic more explicit\n- Catch invalid ports at construction time","design":"1. Create Port class in armadillo/core/value_objects.py\n2. Update type hints in instances/server.py, utils/ports.py, deployment_plan.py, core/types.py (~13 locations)\n3. Update PortManager/PortAllocator to return Port objects\n4. Update all port arithmetic: `port + 1` → `Port(port.value + 1)`\n5. Update command builders and server configs to use port.value\n6. Update all tests\n\nImplementation notes:\n- Port validates range 1024-65535\n- Implements __int__, __eq__, __hash__\n- Provides .value property for int access","acceptance_criteria":"- Port class implemented with range validation\n- All type hints updated from `int` to `Port`\n- PortManager returns Port objects\n- All port construction validated\n- All tests passing\n- No raw integers used for ports","status":"open","priority":4,"issue_type":"chore","created_at":"2025-10-26T11:29:06.094969191+01:00","updated_at":"2025-10-26T11:29:06.094969191+01:00"}
{"id":"armadillo-13","title":"Introduce DeploymentId value object to replace string primitives","description":"Replace string primitive for deployment_id with a proper value object for type safety and validation.\n\nCurrently deployment_id is typed as `str` in multiple locations across instances/ and pytest_plugin/, allowing any string to be used as a deployment identifier.\n\nA DeploymentId value object would:\n- Ensure valid identifier format\n- Prevent confusion with server_id\n- Make deployment tracking more explicit\n- Add validation at construction time","design":"1. Create DeploymentId class in armadillo/core/value_objects.py\n2. Update type hints in instances/manager.py, orchestrator.py, pytest_plugin/plugin.py\n3. Update factory methods and constructors\n4. Update registry/lookup logic\n5. Update all tests\n\nImplementation notes:\n- DeploymentId validates non-empty alphanumeric identifiers\n- Implements __eq__, __hash__ for use in registries\n- Provides .value property for string access","acceptance_criteria":"- DeploymentId class implemented with validation\n- All type hints updated from `str` to `DeploymentId`\n- All construction sites validated\n- All registry/lookup logic updated\n- All tests passing\n- No string primitives used for deployment identifiers","status":"open","priority":4,"issue_type":"chore","created_at":"2025-10-26T11:29:09.04921488+01:00","updated_at":"2025-10-26T11:29:09.04921488+01:00"}
{"id":"armadillo-14","title":"Naming consistency audit and cleanup","description":"Perform final pass to ensure naming conventions are consistent across the codebase.\n\nAudit for:\n- Private methods (_method) that should be public or vice versa\n- Inconsistent naming patterns (get_ vs fetch_, check_ vs verify_)\n- Parameter names that signal intent incorrectly (e.g., _timeout suggesting unused)\n- Methods that violate single responsibility in their naming\n- Public APIs that expose implementation details","design":"1. Systematic audit by module: core/*, instances/*, pytest_plugin/*, utils/*\n2. Document naming conventions in NAMING_CONVENTIONS.md:\n   - When to use get_ vs fetch_ (get = sync lookup, fetch = may involve I/O)\n   - When to use check_ vs verify_ (check = boolean return, verify = raises on failure)\n   - When methods should be private (internal helpers, not part of public API)\n   - Parameter naming (leading underscore only when actually unused)\n3. Create naming consistency guide document\n4. Refactor any violations found\n5. Consider creating linter rules for common patterns","acceptance_criteria":"- Naming conventions documented\n- All inconsistencies identified and catalogued\n- Critical violations fixed\n- Public API naming is consistent and intuitive\n- Private methods are appropriately scoped\n- All tests passing","status":"closed","priority":4,"issue_type":"chore","created_at":"2025-10-26T11:29:12.191103546+01:00","updated_at":"2025-10-30T16:00:22.630191705+01:00","closed_at":"2025-10-30T16:00:22.630191705+01:00"}
{"id":"armadillo-16","title":"Add pytest-timeout as runtime dependency","description":"Add pytest-timeout to pyproject.toml dependencies to enable per-test timeout enforcement via SIGALRM on Linux.\n\nChanges:\n- pyproject.toml: add pytest-timeout~=2.2 to dependencies\n- Verify it works with current pytest version\n- Document in README that per-test timeouts use signal mode (Linux-only, interrupts blocking I/O)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-28T14:17:50.383864841+01:00","updated_at":"2025-10-28T16:08:00.734614021+01:00","closed_at":"2025-10-28T16:08:00.734614021+01:00"}
{"id":"armadillo-17","title":"CLI: add --global-timeout flag and map to ArmadilloConfig.test_timeout","description":"Introduce --global-timeout CLI flag to set the entire test session deadline (currently hard-coded 900s default in ArmadilloConfig).\n\nChanges:\n- armadillo/cli/commands/test.py: add global_timeout field to TestRunOptions\n- Pass global_timeout to ArmadilloConfig constructor as test_timeout\n- Update help text to clarify: --timeout is per-test, --global-timeout is for entire session\n- Update README with both flags and their defaults","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-28T14:17:55.065938821+01:00","updated_at":"2025-10-28T16:09:23.583342919+01:00","closed_at":"2025-10-28T16:09:23.583342919+01:00","dependencies":[{"issue_id":"armadillo-17","depends_on_id":"armadillo-16","type":"blocks","created_at":"2025-10-28T14:17:55.079414794+01:00","created_by":"daemon"}]}
{"id":"armadillo-18","title":"Implement output-idle timeout for pytest subprocess","description":"Add --output-idle-timeout flag to kill pytest if it produces no stdout/stderr for N seconds (detect hung tests that neither timeout nor fail).\n\nDesign:\n- CLI: add output_idle_timeout field (default: None = disabled)\n- armadillo/cli/commands/test.py: instead of subprocess.run, use Popen with line-by-line tee + idle tracking\n- Track last_output_time; if time.monotonic() - last_output_time \u003e threshold, escalate: SIGTERM, wait 5s, SIGKILL\n- Log clear message when idle timeout triggers\n- Update README with flag and recommended value (e.g., 300s for CI)\n\nConstraints:\n- Must not buffer output (line-buffered tee)\n- Must not interfere with user-visible output formatting","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-28T14:18:00.560320187+01:00","updated_at":"2025-10-28T16:11:38.245785559+01:00","closed_at":"2025-10-28T16:11:38.245785559+01:00","dependencies":[{"issue_id":"armadillo-18","depends_on_id":"armadillo-17","type":"blocks","created_at":"2025-10-28T14:18:00.574223136+01:00","created_by":"daemon"}]}
{"id":"armadillo-19","title":"Add integration tests for all three timeout modes","description":"Write framework tests to verify timeout enforcement works correctly for per-test, global, and output-idle timeouts.\n\nTest cases:\n- Per-test timeout: test that sleeps longer than --timeout is killed with pytest-timeout traceback\n- Global timeout: long test suite exceeding --global-timeout triggers ArmadilloConfig.test_timeout enforcement\n- Output-idle timeout: test that hangs without output for longer than --output-idle-timeout is terminated\n- No false positives: tests that finish cleanly within all thresholds pass\n\nLocation: framework_tests/integration/test_timeouts.py","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-28T14:18:05.696439941+01:00","updated_at":"2025-10-28T16:14:16.342232992+01:00","closed_at":"2025-10-28T16:14:16.342232992+01:00","dependencies":[{"issue_id":"armadillo-19","depends_on_id":"armadillo-18","type":"blocks","created_at":"2025-10-28T14:18:05.709716009+01:00","created_by":"daemon"}]}
{"id":"armadillo-21","title":"Print temp directory path at test run start","description":"Display the temporary directory path being used for the test run at startup. This helps with debugging and manual inspection of server data/logs during or after test execution.\n\nCurrently temp_dir is created but path not prominently displayed to user.","design":"Implementation:\n1. In CLI test command (cli/commands/test.py), after config initialization\n2. Print prominent message: \"Test artifacts directory: /path/to/temp/dir\"\n3. Use rich formatting for visibility (bold or highlighted)\n4. Also log at INFO level for structured logs\n\nLocation: Right after test session starts, before server deployment","acceptance_criteria":"- Temp directory path printed at test run start\n- Visible in both compact and verbose modes\n- Path is absolute and easy to copy-paste\n- Logged in structured logs","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-31T14:10:46.64407527+01:00","updated_at":"2025-11-02T11:35:43.057185786+01:00","closed_at":"2025-11-02T11:35:43.057185786+01:00"}
{"id":"armadillo-22","title":"Add --keep-temp-dir option to preserve test artifacts","description":"Add CLI option to control temp directory cleanup behavior. By default, cleanup temp directory on successful test runs. Allow users to preserve artifacts for inspection.\n\nUse cases:\n- Debugging: inspect server data/logs even after successful tests\n- Development: examine state between test runs\n- CI: preserve artifacts for upload before cleanup","design":"Implementation:\n1. Add --keep-temp-dir flag to CLI (default: False)\n2. Add ARMADILLO_KEEP_TEMP_DIR environment variable\n3. Current behavior already has keep_instances_on_failure - extend this\n4. Cleanup logic:\n   - On failure: always keep (existing behavior)\n   - On success with --keep-temp-dir: keep\n   - On success without flag: cleanup temp_dir\n5. Print message when keeping: \"Preserving test artifacts at: /path\"\n\nFiles:\n- cli/commands/test.py: add flag\n- core/config.py: add keep_temp_dir field\n- pytest_plugin/plugin.py: implement cleanup logic in session finish","acceptance_criteria":"- --keep-temp-dir CLI flag works\n- Environment variable ARMADILLO_KEEP_TEMP_DIR works\n- Temp dir cleaned up on success by default\n- Temp dir preserved on success when flag set\n- Temp dir always preserved on failure\n- Clear message when preserving artifacts","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-31T14:10:53.022792506+01:00","updated_at":"2025-11-04T14:43:55.743578564+01:00","closed_at":"2025-11-04T14:43:55.743578564+01:00"}
{"id":"armadillo-23","title":"Add sanitizer support (ASan, UBSan, TSan)","description":"Add support for running ArangoDB with sanitizers (AddressSanitizer, UndefinedBehaviorSanitizer, ThreadSanitizer).\n\nRequirements:\n- Detect if arangod binary is built with sanitizers\n- Set up proper environment variables for sanitizer runtime\n- Configure sanitizer output to temp directory\n- Detect and report sanitizer errors in test results\n- Parse sanitizer reports for failures","design":"Implementation:\n1. Detection (build_detection.py):\n   - Check arangod binary for sanitizer symbols/flags\n   - Detect which sanitizers are enabled\n   \n2. Environment setup (instances/server.py or command_builder.py):\n   - ASAN_OPTIONS: log_path={temp_dir}/asan.log, detect_leaks=1, etc.\n   - UBSAN_OPTIONS: log_path={temp_dir}/ubsan.log, print_stacktrace=1\n   - TSAN_OPTIONS: log_path={temp_dir}/tsan.log, history_size=7\n   \n3. Report collection (results/collector.py or new sanitizer_analyzer.py):\n   - Check for sanitizer log files in temp_dir after test\n   - Parse reports for errors\n   - Mark test as failed if sanitizer errors found\n   - Include sanitizer output in test failure details\n   \n4. CLI support:\n   - Auto-detect or --sanitizer flag\n   - --sanitizer-options for custom runtime options\n\nCommon sanitizer options:\n- ASan: detect_leaks, detect_stack_use_after_return, check_initialization_order\n- UBSan: print_stacktrace\n- TSan: history_size, io_sync","acceptance_criteria":"- Sanitizer detection works for ASan/UBSan/TSan\n- Environment variables correctly set for arangod process\n- Sanitizer logs written to temp directory\n- Sanitizer errors detected and reported\n- Tests fail when sanitizer finds issues\n- Sanitizer output included in failure details","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-31T14:10:58.805695063+01:00","updated_at":"2025-10-31T14:10:58.805695063+01:00"}
{"id":"armadillo-24","title":"Add option to abort arangod with SIGABRT for coredump generation","description":"Add ability to send SIGABRT to arangod processes instead of graceful shutdown (SIGTERM). This triggers coredump generation when core dumps are enabled, useful for debugging.\n\nUse cases:\n- Post-mortem debugging: generate coredump even from successful tests\n- CI debugging: capture full server state for analysis\n- Development: inspect server internals after specific test scenarios","design":"Implementation:\n1. Add --coredump-on-exit flag (or similar name)\n2. Add per-test marker: @pytest.mark.coredump_on_exit\n3. Modify ProcessSupervisor.stop() to accept signal parameter\n4. When enabled, send SIGABRT instead of SIGTERM\n5. Wait for coredump generation (may take time)\n6. Detect if coredumps actually generated (check /proc/sys/kernel/core_pattern)\n\nFiles:\n- core/process.py: add signal parameter to stop methods\n- instances/server.py: pass signal based on config/marker\n- core/config.py: add coredump_on_exit option\n- pytest_plugin/plugin.py: check for marker, configure accordingly\n\nSafety:\n- Only use SIGABRT during shutdown, not during normal operation\n- Document that this requires proper core dump configuration\n- Warn if core dumps not enabled in system","acceptance_criteria":"- --coredump-on-exit CLI flag works\n- Per-test marker @pytest.mark.coredump_on_exit works\n- SIGABRT sent to arangod on shutdown when enabled\n- Coredumps generated (if system configured)\n- Warning shown if coredumps not enabled in system\n- Documentation updated with core dump setup instructions","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-31T14:11:04.519385205+01:00","updated_at":"2025-10-31T14:11:04.519385205+01:00"}
{"id":"armadillo-25","title":"Implement coredump analysis with gdb/lldb","description":"Add automatic coredump analysis when server crashes or SIGABRT is sent. Extract backtrace, thread information, and variable state from coredump files.\n\nThis helps with:\n- Automatic crash diagnosis in CI\n- Rich failure reports with stack traces\n- Post-mortem debugging without manual gdb session","design":"Implementation:\n1. Coredump detection (utils/coredump.py or results/crash_analyzer.py):\n   - Find coredumps in temp_dir or system location\n   - Match coredump to arangod process (PID, timestamp)\n   \n2. Debugger abstraction:\n   - Support both gdb and lldb (configurable)\n   - --debugger flag: gdb (default), lldb, or auto-detect\n   - Abstract interface: DebuggerInterface with GdbDebugger and LldbDebugger implementations\n   \n3. GDB automation:\n   - Run: gdb -batch -ex \"commands\" core.file binary\n   - Commands: 'bt full', 'info threads', 'thread apply all bt'\n   \n4. LLDB automation:\n   - Run: lldb -c core.file -b -o \"commands\" binary\n   - Commands: 'bt all', 'thread backtrace all', 'thread list'\n   \n5. Report generation:\n   - Parse gdb/lldb output (different formats)\n   - Format as structured data\n   - Include in test failure details\n   - Save as separate artifact (coredump_analysis.txt)\n   \n6. Integration:\n   - Run analysis in pytest_plugin after test/session\n   - Detect crashes via ProcessSupervisor crash detection\n   - Attach analysis to failed test result\n   \n7. Configuration:\n   - --analyze-coredumps flag (default: true if coredumps found)\n   - --debugger {gdb,lldb,auto} flag\n   - Auto-detect: check which debugger is available\n   - Gracefully handle missing debugger or debug symbols\n\nFiles:\n- utils/coredump.py: coredump detection\n- utils/debugger.py: debugger abstraction (GdbDebugger, LldbDebugger)\n- results/crash_analyzer.py: analysis orchestration\n- pytest_plugin/plugin.py: integrate with test lifecycle","acceptance_criteria":"- Coredumps automatically detected\n- Both gdb and lldb supported\n- --debugger flag for selection (gdb/lldb/auto)\n- Backtrace extracted and formatted from both debuggers\n- Thread information included\n- Analysis attached to test failure report\n- Graceful handling when debugger missing\n- Works with both crash and SIGABRT coredumps\n- Auto-detection picks available debugger","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-31T14:11:13.480320649+01:00","updated_at":"2025-10-31T14:12:23.394510934+01:00"}
{"id":"armadillo-26","title":"Implement log-based crash analysis (fallback when no coredump)","description":"When server crashes but no coredump available, analyze log files for crash information. ArangoDB prints stack traces to logs on crash - extract and format these for reporting.\n\nFallback for when:\n- Coredumps disabled in system\n- Coredump not found/matched\n- Quick crash diagnosis without full coredump analysis","design":"Implementation:\n1. Log analysis (utils/log_analyzer.py):\n   - Search arangod logs for crash indicators\n   - Patterns: \"FATAL\", \"Signal\", \"Backtrace:\", stack trace lines\n   - Extract relevant sections around crash\n   \n2. Stack trace extraction:\n   - Parse ArangoDB log format for stack traces\n   - Extract function names, addresses, source locations\n   - Format for readability\n   \n3. Integration:\n   - Run when ProcessSupervisor detects crash\n   - Run as fallback if coredump analysis fails/unavailable\n   - Include in test failure details\n   \n4. Report format:\n   - Extracted stack trace\n   - Signal information\n   - Surrounding log context\n   - Save as crash_analysis_from_logs.txt\n\nFiles:\n- utils/log_analyzer.py: log parsing and crash detection\n- results/crash_analyzer.py: coordinate with coredump analysis\n- pytest_plugin/plugin.py: invoke on crash detection\n\nPriority: Run coredump analysis first if available, fall back to logs","acceptance_criteria":"- Log files searched for crash indicators\n- Stack traces extracted from logs\n- Crash information formatted in report\n- Works as fallback when no coredump\n- Attached to test failure details\n- Handles various ArangoDB log formats","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-31T14:11:22.287130825+01:00","updated_at":"2025-10-31T14:11:22.287130825+01:00"}
{"id":"armadillo-27","title":"Create artifact archive for CI publishing","description":"Add option to create compressed archive of entire temp directory for CI artifact publishing. Archive should include all logs, data, coredumps, analysis reports, and test results.\n\nUse case: CI pipelines need to publish test artifacts for later inspection, especially on failures.","design":"Implementation:\n1. Add --create-archive or --archive-artifacts flag\n2. Archive creation (utils/archive.py or results/archiver.py):\n   - Create tar.gz or zip of temp_dir\n   - Include: server logs, data dirs, coredumps, analysis reports, test results\n   - Exclude: large unnecessary files (database files if needed)\n   - Name: armadillo-artifacts-{timestamp}-{session-id}.tar.gz\n   \n3. Timing:\n   - Create archive at end of test session (pytest_sessionfinish)\n   - Before temp directory cleanup\n   - Even on failures\n   \n4. Location:\n   - Save archive to output_dir or current directory\n   - Print path prominently for CI to find\n   \n5. Optimization:\n   - Option to compress heavily (slower) vs faster compression\n   - Option to exclude specific patterns\n   - Archive only on failure (--archive-on-failure)\n\nFiles:\n- utils/archive.py: compression logic\n- cli/commands/test.py: add flags\n- pytest_plugin/plugin.py: trigger at session end\n- core/config.py: archive options\n\nCI integration:\n- Archive path predictable for CI scripts\n- Exit code preserved even if archive fails","acceptance_criteria":"- --create-archive flag creates tar.gz of temp dir\n- Archive includes all relevant artifacts\n- Archive created before cleanup\n- Archive path printed clearly\n- Works even when tests fail\n- Optional --archive-on-failure variant\n- Reasonable compression (not too slow)\n- Predictable archive naming for CI scripts","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-31T14:11:32.616597857+01:00","updated_at":"2025-10-31T14:11:32.616597857+01:00"}
{"id":"armadillo-28","title":"Refactor pytest plugin to use single shared ApplicationContext","description":"Currently each InstanceManager creates its own ApplicationContext via get_instance_manager(), leading to multiple independent contexts and no single source of truth for session artifacts location.\n\nThis makes it difficult to:\n- Report where test artifacts are stored\n- Share configuration across deployments\n- Track session-level resources\n\nDesign flaw: get_instance_manager() factory creates new context each time, but pytest session should have ONE context shared by all deployments.","design":"Refactor to single ApplicationContext per pytest session:\n\n1. Pytest plugin creates ApplicationContext at session start:\n   - Generate session_id\n   - Create context from framework config\n   - Set session_id on filesystem service\n   - Store as _session_app_context\n\n2. Update get_instance_manager() signature:\n   - Add optional app_context parameter\n   - If provided, use it; if None, create new one (backward compat)\n   \n3. Update pytest plugin deployment methods:\n   - Pass _session_app_context to get_instance_manager()\n   - All session deployments share same context\n   \n4. Clean artifact directory reporting:\n   - Simply use _session_app_context.filesystem.work_dir()\n   - No hasattr checks or private attribute access\n   \n5. Benefits:\n   - Single source of truth for session resources\n   - Clean access to artifacts directory\n   - Shared port allocator (better port management)\n   - Consistent filesystem paths across deployments\n\nFiles:\n- pytest_plugin/plugin.py: create and manage session context\n- instances/manager.py: update get_instance_manager() signature\n- All fixtures: pass session context","acceptance_criteria":"- Pytest plugin creates ONE ApplicationContext per session\n- get_instance_manager() accepts optional app_context parameter\n- All session deployments use shared context\n- Clean access to artifacts directory (no hasattr hacks)\n- Backward compatibility maintained for direct get_instance_manager() calls\n- All tests passing","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-31T14:26:59.993554441+01:00","updated_at":"2025-11-02T11:35:41.815509316+01:00","closed_at":"2025-11-02T11:35:41.815509316+01:00","dependencies":[{"issue_id":"armadillo-28","depends_on_id":"armadillo-21","type":"blocks","created_at":"2025-10-31T14:27:00.007456459+01:00","created_by":"daemon"}]}
{"id":"armadillo-29","title":"Ensure single shared ApplicationContext across entire framework","description":"After armadillo-28, we still had 4 fixtures creating their own ApplicationContext instances instead of using the shared session context:\n1. arango_single_server (session)\n2. arango_single_server_function (function)  \n3. arango_cluster (session)\n4. arango_cluster_function (function)\n\nThis caused:\n- Multiple session IDs (breaks artifact directory tracking)\n- Separate port allocators (possible port conflicts)\n- Inconsistent configuration\n- Wasted memory overhead\n\nGoal: ONE ApplicationContext per pytest session, period.","design":"Update all 4 fixtures to use _plugin._session_app_context:\n\nBefore:\n```python\napp_context = ApplicationContext.create(get_config())\nmanager = get_instance_manager(deployment_id, app_context)\n```\n\nAfter:\n```python\nmanager = get_instance_manager(deployment_id, _plugin._session_app_context)\n```\n\nRemove unnecessary imports of ApplicationContext and get_config from fixtures.\n\nVerified production code has only ONE place creating ApplicationContext: pytest_sessionstart hook.","acceptance_criteria":"- All 4 fixtures use _plugin._session_app_context\n- No ApplicationContext.create() calls except in pytest_sessionstart\n- All 499+ tests passing\n- Single session ID for all deployments in a test run\n- Shared port allocator across all fixtures","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-02T11:47:54.643637229+01:00","updated_at":"2025-11-02T11:47:59.480529524+01:00","closed_at":"2025-11-02T11:47:59.480529524+01:00"}
{"id":"armadillo-30","title":"Rename process_id to server_id for clarity","description":"Current naming is misleading: 'process_id' throughout the codebase refers to logical server identifiers like \"agent_0\", \"dbserver_1\", \"coordinator_0\" - NOT OS-level process IDs (PIDs).\n\nThis causes confusion:\n- process_id in ProcessSupervisor: \"agent_0\" (string)\n- ProcessInfo.pid: 12345 (int) - actual OS PID\n- crash_state keys: \"agent_0\" (string)\n- ArangoServer.server_id: \"agent_0\" (string)\n\nThe terminology mixes logical identifiers with process management, making code harder to understand.","design":"Systematic rename of process_id to server_id where it refers to logical identifiers:\n\nFiles to update:\n- core/process.py: ProcessSupervisor methods and attributes\n  - start(server_id, ...) instead of start(process_id, ...)\n  - _crash_state: Dict[str, CrashInfo] keys\n  - _processes, _process_info dictionary keys\n  - get_crash_state(server_id) parameter\n  - Log messages and error messages\n  \n- instances/server.py: All call sites to start_supervised_process()\n- instances/manager.py: Any references\n- instances/orchestrator.py: Any references\n- pytest_plugin/plugin.py: Crash state iteration\n\nKeep OS PID references as 'pid' (ProcessInfo.pid, process.pid, etc.)\n\nThis is pure refactoring with no functional changes.","acceptance_criteria":"- All 'process_id' parameters renamed to 'server_id' where referring to logical identifiers\n- OS PIDs still called 'pid'\n- Dictionary keys updated (crash_state, processes, process_info)\n- Log messages updated for consistency\n- All tests passing\n- No functional changes, pure refactoring","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-02T18:40:43.160182264+01:00","updated_at":"2025-11-02T18:48:47.580795907+01:00","closed_at":"2025-11-02T18:48:47.580795907+01:00"}
{"id":"armadillo-31","title":"Introduce ServerId value object for type safety","description":"After renaming process_id to server_id (armadillo-30), introduce a ServerId value object to replace string primitives with proper type safety.\n\nCurrently server_id is typed as `str` in ~27+ locations across the codebase (instances/server.py, manager.py, server_registry.py, deployment_planner.py, core/process.py, etc.), leading to potential bugs where any string can be passed.\n\nBenefits:\n- Type safety: Can't confuse server IDs with arbitrary strings\n- Validation: Prevent empty/invalid identifiers at construction time\n- Explicit relationship between logical ID, role, and OS PID\n- Can add helper methods (is_agent(), is_coordinator(), is_running())\n- Self-documenting code\n- Catches errors at construction time rather than runtime\n\nTrade-offs:\n- More complexity than plain strings\n- Need to update Dict[str, X] to Dict[ServerId, X]\n- Serialization handling required\n- Larger refactoring effort (~27+ locations to update)\n\nThis should be evaluated based on:\n- How often we need both name + PID together\n- Whether type confusion is causing actual bugs\n- Team preference for value objects vs primitives","design":"Two implementation options:\n\n## Option 1: Full Value Object (Recommended)\n\nCreate armadillo/core/value_objects.py with comprehensive ServerId class:\n\n```python\n@dataclass(frozen=True)\nclass ServerId:\n    \\\"\\\"\\\"Immutable identifier for a server instance.\\\"\\\"\\\"\n    name: str  # \"agent_0\", \"dbserver_1\"\n    role: ServerRole\n    pid: Optional[int] = None  # OS process ID when running\n    \n    def __post_init__(self):\n        if not self.name or not self.name.strip():\n            raise ValueError(\"ServerId name cannot be empty\")\n        if not self.name.replace(\"_\", \"\").isalnum():\n            raise ValueError(f\"ServerId must be alphanumeric: {self.name}\")\n    \n    def __str__(self) -\u003e str:\n        return self.name\n    \n    def __hash__(self) -\u003e int:\n        return hash(self.name)\n    \n    def __eq__(self, other) -\u003e bool:\n        if isinstance(other, ServerId):\n            return self.name == other.name\n        return False\n    \n    @property\n    def value(self) -\u003e str:\n        \\\"\\\"\\\"Get string value for legacy code.\\\"\\\"\\\"\n        return self.name\n    \n    def is_agent(self) -\u003e bool:\n        return self.role == ServerRole.AGENT\n    \n    def is_coordinator(self) -\u003e bool:\n        return self.role == ServerRole.COORDINATOR\n    \n    def is_dbserver(self) -\u003e bool:\n        return self.role == ServerRole.DBSERVER\n    \n    def is_running(self) -\u003e bool:\n        return self.pid is not None\n```\n\n## Option 2: Lightweight NewType (Alternative)\n\n```python\nfrom typing import NewType\nServerId = NewType('ServerId', str)\n```\n\nThis gives some type checking without full value object complexity, but no validation or helper methods.\n\n## Implementation Plan\n\nFiles to update (~27 locations):\n1. Create core/value_objects.py with ServerId class\n2. Update type hints:\n   - instances/server.py\n   - instances/manager.py\n   - instances/server_registry.py\n   - instances/deployment_planner.py\n   - core/process.py (ProcessSupervisor)\n3. Update factory methods to construct ServerId objects\n4. Update comparison logic: `server_id == \"foo\"` → `server_id.value == \"foo\"` or `str(server_id) == \"foo\"`\n5. Update dictionaries: Dict[str, X] → Dict[ServerId, X]\n6. Update serialization in results collector\n7. Add __str__ support for logging (already in design)\n8. Update all tests to use ServerId constructor","acceptance_criteria":"- ServerId class or NewType implemented\n- ProcessSupervisor uses ServerId consistently\n- Dictionaries keyed by ServerId\n- Serialization/deserialization working\n- Helper methods implemented (if full class)\n- All tests updated and passing\n- Performance impact evaluated (dict lookups, hashing)\n\nSuccess criteria:\n- Type checker catches mixing server IDs with other strings\n- Code is more self-documenting\n- No significant performance regression","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-11-02T18:43:24.927591633+01:00","updated_at":"2025-11-03T18:51:25.130843767+01:00","closed_at":"2025-11-03T18:51:25.130843767+01:00","dependencies":[{"issue_id":"armadillo-31","depends_on_id":"armadillo-30","type":"blocks","created_at":"2025-11-02T18:43:24.94188379+01:00","created_by":"daemon"}]}
{"id":"armadillo-32","title":"Create ServerId and ServerContext value objects","description":"Create the foundational value objects for server identification and context.\n\nThis is Phase 1 of the ServerId refactoring (armadillo-31).\n\nFiles to create:\n- armadillo/core/value_objects.py (new file)\n\nIncludes:\n1. ServerId: Pure immutable identifier with validation\n2. ServerContext: Enriched snapshot for logging/diagnostics with PID\n3. Unit tests for both classes","design":"ServerId implementation:\n- @dataclass(frozen=True) with single field: value: str\n- Validation: non-empty, alphanumeric with _ or -\n- __str__, __hash__, __eq__ for use as dict keys\n- Simple string wrapper, no role/pid coupling\n\nServerContext implementation:\n- Fields: server_id: ServerId, role: ServerRole, pid: Optional[int], port: Optional[int]\n- __str__ formats as \"agent_0[pid:12345]\" or \"agent_0[not running]\"\n- Helper methods: is_running(), is_agent(), is_coordinator(), is_dbserver()\n- Immutable snapshot for diagnostics\n\nExport both from armadillo/core/__init__.py","acceptance_criteria":"- armadillo/core/value_objects.py created\n- ServerId validates input correctly\n- ServerId works as dict key (hashable, comparable)\n- ServerContext formats properly for logs\n- Both exported from core module\n- Unit tests in framework_tests/unit/test_core_value_objects.py\n- All existing tests still pass","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:18.84064336+01:00","updated_at":"2025-11-03T16:29:04.067171297+01:00","closed_at":"2025-11-03T16:29:04.067171297+01:00","dependencies":[{"issue_id":"armadillo-32","depends_on_id":"armadillo-31","type":"parent-child","created_at":"2025-11-03T16:17:08.106305135+01:00","created_by":"daemon"}]}
{"id":"armadillo-33","title":"Update ProcessSupervisor to use ServerId","description":"Refactor core/process.py ProcessSupervisor to use ServerId instead of string primitives.\n\nThis is Phase 2 of the ServerId refactoring (armadillo-31).\n\nChanges:\n- All internal dictionaries keyed by ServerId\n- All method signatures accept ServerId\n- Add get_server_context() method\n- Update logging to use ServerContext where beneficial","design":"Update ProcessSupervisor:\n1. Change dictionary types:\n   - _processes: Dict[ServerId, subprocess.Popen]\n   - _process_info: Dict[ServerId, ProcessInfo]\n   - _monitoring_threads: Dict[ServerId, threading.Thread]\n   - _streaming_threads: Dict[ServerId, threading.Thread]\n   - _crash_state: Dict[ServerId, CrashInfo]\n\n2. Update method signatures to accept ServerId:\n   - start(server_id: ServerId, ...)\n   - stop(server_id: ServerId, ...)\n   - All internal methods\n\n3. Add: get_server_context(server_id: ServerId, role: ServerRole) -\u003e Optional[ServerContext]\n   - Returns snapshot with current PID if running\n\n4. Update logging to show PID via ServerContext\n\nFile: armadillo/core/process.py","acceptance_criteria":"- All ProcessSupervisor dictionaries use ServerId keys\n- All method signatures updated\n- get_server_context() implemented\n- Crash state tracking uses ServerId\n- Logs show server_id[pid:X] format\n- All tests passing","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:24.991386094+01:00","updated_at":"2025-11-03T16:48:58.331053209+01:00","closed_at":"2025-11-03T16:48:58.331053209+01:00","dependencies":[{"issue_id":"armadillo-33","depends_on_id":"armadillo-32","type":"blocks","created_at":"2025-11-03T16:16:25.008951611+01:00","created_by":"daemon"}]}
{"id":"armadillo-34","title":"Update logging functions to support ServerContext","description":"Enhance armadillo/core/log.py to support enriched logging with ServerContext while maintaining backward compatibility.\n\nThis enables logs to show both server_id and PID together: \"Server agent_0[pid:12345] started\"","design":"Update log_server_event():\n1. Add overload accepting ServerContext parameter\n2. When ServerContext provided:\n   - Use str(context) in log message → \"agent_0[pid:12345]\"\n   - Add structured fields: server_id, pid, role to extra dict\n3. Keep backward compatible version accepting server_id: str\n4. Update docstrings with examples\n\nFile: armadillo/core/log.py","acceptance_criteria":"- log_server_event() accepts ServerContext\n- Logs format as \"Server agent_0[pid:12345] event\"\n- Structured logging includes pid field\n- Backward compatibility maintained\n- All tests passing","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:28.791905323+01:00","updated_at":"2025-11-03T17:09:57.405945318+01:00","closed_at":"2025-11-03T17:09:57.405945318+01:00","dependencies":[{"issue_id":"armadillo-34","depends_on_id":"armadillo-32","type":"blocks","created_at":"2025-11-03T16:16:28.810680426+01:00","created_by":"daemon"}]}
{"id":"armadillo-35","title":"Update ArangoServer and ServerFactory to use ServerId","description":"Refactor server instance management to use ServerId primitives.\n\nThis is Phase 3 of the ServerId refactoring (armadillo-31).\n\nFiles:\n- instances/server.py: ArangoServer class\n- instances/server_factory.py: ServerFactory classes\n- instances/server_registry.py: ServerRegistry","design":"instances/server.py:\n- ArangoServer.__init__: server_id: ServerId parameter\n- Factory methods accept str | ServerId, normalize to ServerId\n- Add get_context() -\u003e ServerContext method\n- Update all logging to use ServerContext\n\ninstances/server_factory.py:\n- _generate_server_id() returns ServerId(f\"agent_{i}\")\n- create_server_instances() returns Dict[ServerId, ArangoServer]\n- Update all type hints\n\ninstances/server_registry.py:\n- _servers: Dict[ServerId, ArangoServer]\n- All methods accept/return ServerId\n- Update type hints throughout","acceptance_criteria":"- ArangoServer uses ServerId internally\n- Factory generates ServerId objects\n- Registry keyed by ServerId\n- All type hints updated\n- Logging shows PID via ServerContext\n- All tests passing","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:33.086968088+01:00","updated_at":"2025-11-03T17:23:28.702837153+01:00","closed_at":"2025-11-03T17:23:28.702837153+01:00","dependencies":[{"issue_id":"armadillo-35","depends_on_id":"armadillo-33","type":"blocks","created_at":"2025-11-03T16:16:33.105345381+01:00","created_by":"daemon"},{"issue_id":"armadillo-35","depends_on_id":"armadillo-34","type":"blocks","created_at":"2025-11-03T16:16:33.113117145+01:00","created_by":"daemon"}]}
{"id":"armadillo-36","title":"Update deployment orchestration to use ServerId","description":"Update deployment planning and orchestration components to use ServerId.\n\nThis is Phase 4 of the ServerId refactoring (armadillo-31).\n\nFiles:\n- instances/deployment_plan.py\n- instances/deployment_planner.py\n- instances/deployment_orchestrator.py\n- instances/manager.py","design":"deployment_plan.py:\n- create_single_server_plan(server_id: str | ServerId, ...) \n- Normalize to ServerId internally\n\ndeployment_orchestrator.py:\n- _startup_order: List[ServerId]\n- Update all method signatures\n- Use ServerContext for error reporting\n\nmanager.py:\n- Review all server_id usage\n- Update any method signatures\n- Ensure consistency","acceptance_criteria":"- Deployment planning uses ServerId\n- Orchestrator tracks order with ServerId\n- Manager methods accept ServerId\n- Error messages include PID via ServerContext\n- All tests passing","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:37.26618285+01:00","updated_at":"2025-11-03T17:29:54.066668929+01:00","closed_at":"2025-11-03T17:29:54.066668929+01:00","dependencies":[{"issue_id":"armadillo-36","depends_on_id":"armadillo-35","type":"blocks","created_at":"2025-11-03T16:16:37.283480354+01:00","created_by":"daemon"}]}
{"id":"armadillo-37","title":"Update health checking and command building for ServerId","description":"Update remaining instance management components to use ServerId.\n\nThis is Phase 5 of the ServerId refactoring (armadillo-31).\n\nFiles:\n- instances/health_checker.py\n- instances/cluster_bootstrapper.py\n- instances/command_builder.py","design":"health_checker.py:\n- Update method signatures to accept ServerId\n- Internal HTTP checks still use string URLs\n\ncluster_bootstrapper.py:\n- Update any server_id references\n- Ensure consistency with ServerId\n\ncommand_builder.py:\n- Review ServerCommandParams\n- Update logging to use ServerId\n- Keep command generation working with strings","acceptance_criteria":"- Health checker accepts ServerId\n- Cluster bootstrapper uses ServerId\n- Command builder handles ServerId\n- All components consistent\n- All tests passing","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:41.524768908+01:00","updated_at":"2025-11-03T18:19:33.256478643+01:00","closed_at":"2025-11-03T18:19:33.256478643+01:00","dependencies":[{"issue_id":"armadillo-37","depends_on_id":"armadillo-36","type":"blocks","created_at":"2025-11-03T16:16:41.537179857+01:00","created_by":"daemon"}]}
{"id":"armadillo-38","title":"Update pytest plugin and results serialization for ServerId","description":"Handle ServerId in pytest integration and result collection, maintaining JSON backward compatibility.\n\nThis is Phase 6-7 of the ServerId refactoring (armadillo-31).\n\nFiles:\n- pytest_plugin/plugin.py\n- results/collector.py (and related)","design":"pytest_plugin/plugin.py:\n- Update crash state iteration: Dict[ServerId, CrashInfo]\n- Convert ServerId to string for pytest reporting\n- Ensure fixture compatibility\n\nresults/collector.py:\n- Serialize ServerId → str(server_id) for JSON\n- Keep JSON format: {\"server_id\": \"agent_0\"} (backward compatible)\n- No change to external schema\n- Add tests for serialization roundtrip","acceptance_criteria":"- Pytest plugin handles ServerId\n- Crash reporting works correctly\n- JSON serialization maintains schema\n- Backward compatibility verified\n- All integration tests passing","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:47.457158657+01:00","updated_at":"2025-11-03T18:50:53.976818334+01:00","closed_at":"2025-11-03T18:50:53.976818334+01:00","dependencies":[{"issue_id":"armadillo-38","depends_on_id":"armadillo-37","type":"blocks","created_at":"2025-11-03T16:16:47.477087689+01:00","created_by":"daemon"}]}
{"id":"armadillo-39","title":"Update all framework tests to use ServerId","description":"Update framework unit and integration tests to construct and use ServerId objects correctly.\n\nFinal phase of ServerId refactoring (armadillo-31).\n\nScope:\n- framework_tests/unit/test_core_*.py\n- framework_tests/unit/test_instances_*.py\n- Any other test files using server_id","design":"Test updates:\n1. Update server_id construction to use ServerId()\n2. Test ServerId as dict keys\n3. Update assertions for ServerId equality\n4. Ensure mock objects return ServerId\n5. Add regression tests for string/ServerId confusion\n\nRun full test suite to verify:\n- All 499+ tests passing\n- Type checking with mypy passes\n- No string primitives used for server IDs","acceptance_criteria":"- All unit tests use ServerId\n- All integration tests pass\n- Type checker (mypy) validates ServerId usage\n- No regressions introduced\n- Performance benchmarks show negligible impact\n- Documentation updated if needed","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T16:16:53.202081189+01:00","updated_at":"2025-11-03T18:56:47.970600035+01:00","closed_at":"2025-11-03T18:56:47.970600035+01:00","dependencies":[{"issue_id":"armadillo-39","depends_on_id":"armadillo-38","type":"blocks","created_at":"2025-11-03T16:16:53.212003543+01:00","created_by":"daemon"}]}
{"id":"armadillo-9","title":"Establish consistent async/sync patterns","description":"Codebase has mixed sync/async patterns causing confusion and potential performance issues. Need to choose one paradigm and apply consistently, with explicit adapters where needed.","design":"Decision: Go full async where appropriate (I/O-bound operations)\n\n1. Audit sync/async boundary:\n   - Mark each module as Pure Async, Pure Sync, or Mixed\n   - Identify which modules need conversion\n   \n2. Convert core classes to async:\n   - instances/server.py (start, stop, health checks)\n   - instances/manager.py (deployment operations)\n   - instances/health_checker.py (all checks)\n   \n3. Create sync adapters module:\n   - sync_adapters.py with explicit sync wrappers\n   - Document when/why to use each adapter\n   - Warning about event loop creation costs\n   \n4. Update tests:\n   - Use @pytest.mark.asyncio for async tests\n   - Update fixtures to support async\n   - Document async testing patterns\n   \n5. Keep pure computation sync (utils, validation, etc.)","acceptance_criteria":"- Clear async/sync boundary documented\n- Core I/O operations are async\n- Sync adapters isolated in one module\n- Tests updated to use async patterns\n- No asyncio.run() in class methods\n- All tests passing","notes":"DEFERRED - Complex pytest-asyncio integration issues\n\nInvestigation findings (Oct 27, 2025):\n\n**Test Integration Problem:**\nWhen converting tests to @pytest.mark.asyncio with async/await:\n- Individual async tests PASS when run alone\n- Multiple async tests together FAIL during pytest-asyncio setup\n- Error: PermissionError: [Errno 1] Operation not permitted (in selectors.py during event loop creation)\n- Also: AttributeError: '_UnixSelectorEventLoop' object has no attribute '_signal_handlers' (during cleanup)\n\n**Environment:**\n- Python 3.13.3\n- pytest-asyncio 1.1.0\n- WSL2\n- ulimit -n: 1048576 (NOT resource exhaustion)\n\n**What Was Tried:**\n1. asyncio.run() in sync tests - caused event loop conflicts\n2. Creating server instances in async test context - event loop cleanup errors\n3. Module-scoped event loops - not fully tested\n4. Reverting to sync tests - still got setup errors\n\n**Root Cause:**\nUNKNOWN. The interaction between pytest-asyncio, Python 3.13, test class fixtures (setup_method), and event loop management is complex.\n\n**Decision:**\nAsync conversion work has been rolled back (git reset to 634470b1ebb).\nCurrent synchronous approach works perfectly: 494 tests passing, 2 skipped.\n\n**To Revisit:**\n- Investigate pytest-asyncio event loop management in depth\n- Consider alternative testing approaches\n- Check if Python 3.14 or newer pytest-asyncio versions resolve the issue\n- May need to restructure test classes to avoid setup_method with async tests","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-25T11:24:56.748859382+02:00","updated_at":"2025-10-27T14:19:35.244487531+01:00"}
