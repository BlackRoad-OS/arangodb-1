<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="1" failures="0" skipped="0" tests="1" time="3.694" timestamp="2025-09-17T17:34:53.141474+02:00" hostname="Ryzen-ArangoDB"><testcase classname="tests.shell_api.test_statistics.TestStatisticsAPI" name="test_statistics_correct_endpoint" time="3.565"><error message="failed on setup with &quot;armadillo.core.errors.ServerStartupError: Failed to deploy servers: Failed to start database server dbserver_3: Failed to start server dbserver_3: Failed to start process dbserver_3: Process dbserver_3 died during startup&quot;">self = &lt;armadillo.core.process.ProcessSupervisor object at 0x7377a657fd90&gt;
process_id = 'dbserver_3'
command = ['/home/mpoeter/dev/arangodb/arango_next4/build-clang/bin/arangod', '--configuration', 'etc/testing/arangod-dbserver.conf', '--define', 'TOP_DIR=/home/mpoeter/dev/arangodb/arango_next4', '--server.endpoint', ...]
cwd = PosixPath('/home/mpoeter/dev/arangodb/arango_next4'), env = None
startup_timeout = 60.0
readiness_check = &lt;function ArangoServer.start.&lt;locals&gt;.&lt;lambda&gt; at 0x7377a4e89da0&gt;
inherit_console = False

    def start(self,
             process_id: str,
             command: List[str],
             cwd: Optional[Path] = None,
             env: Optional[Dict[str, str]] = None,
             startup_timeout: float = 30.0,
             readiness_check: Optional[Callable[[], bool]] = None,
             inherit_console: bool = False) -&gt; ProcessInfo:
        """Start a supervised process.
    
        Args:
            process_id: Unique identifier for the process
            command: Command and arguments to execute
            cwd: Working directory (optional)
            env: Environment variables (optional)
            startup_timeout: Maximum time to wait for startup (seconds)
            readiness_check: Function to check if process is ready (optional)
            inherit_console: If True, process inherits parent's stdout/stderr directly
                           (no buffering delays). If False, output is captured and
                           streamed with [process_id] prefixes (default: False)
    
        Returns:
            ProcessInfo object with process details
        """
    
        if process_id in self._processes:
            raise ProcessStartupError(f"Process {process_id} is already running")
    
        effective_timeout = clamp_timeout(startup_timeout, f"startup_{process_id}")
    
        log_process_event(logger, "supervisor.start", process_id=process_id,
                         command=command)
    
        # Log complete command line for debugging
        logger.info(f"=== STARTING PROCESS: {process_id} ===")
        logger.info(f"Working directory: {cwd or Path.cwd()}")
        logger.info(f"Complete command line:")
        logger.info(f"  {' '.join(command)}")
        if env:
            logger.info(f"Environment variables: {env}")
        logger.info(f"======================================")
    
        try:
            # Configure stdout/stderr based on inheritance mode
            if inherit_console:
                # Direct console inheritance - no buffering, perfect timing
                stdout_config = None  # Inherit parent's stdout
                stderr_config = None  # Inherit parent's stderr
                use_streaming = False
            else:
                # Captured output with streaming - adds process ID prefixes
                stdout_config = subprocess.PIPE
                stderr_config = subprocess.STDOUT  # Merge stderr into stdout
                use_streaming = True
    
            # Start the process in its own process group for proper cleanup of children
            process = subprocess.Popen(
                command,
                cwd=cwd,
                env=env,
                stdout=stdout_config,
                stderr=stderr_config,
                text=True if use_streaming else None,
                bufsize=1 if use_streaming else -1,  # Line buffered only for streaming
                universal_newlines=True if use_streaming else None,
                start_new_session=True  # Create new process group for proper child cleanup
            )
    
            # Store process information
            process_info = ProcessInfo(
                pid=process.pid,
                command=command,
                start_time=time.time(),
                working_dir=cwd or Path.cwd(),
                env=env or {}
            )
    
            self._processes[process_id] = process
            self._process_info[process_id] = process_info
    
            log_process_event(logger, "supervisor.started",
                            process_id=process_id, pid=process.pid)
    
            # Start output streaming thread (only if not inheriting console)
            if use_streaming:
                self._start_output_streaming(process_id)
    
            # Wait for readiness if check provided
            if readiness_check:
&gt;               self._wait_for_readiness(process_id, readiness_check, effective_timeout)

armadillo/core/process.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;armadillo.core.process.ProcessSupervisor object at 0x7377a657fd90&gt;
process_id = 'dbserver_3'
readiness_check = &lt;function ArangoServer.start.&lt;locals&gt;.&lt;lambda&gt; at 0x7377a4e89da0&gt;
timeout = 59.99961471557617

    def _wait_for_readiness(self,
                           process_id: str,
                           readiness_check: Callable[[], bool],
                           timeout: float) -&gt; None:
        """Wait for process to become ready."""
        start_time = time.time()
    
        while time.time() - start_time &lt; timeout:
            if not self.is_running(process_id):
                # Try to capture any output from the dead process
                error_output = ""
                try:
                    if process_id in self._processes:
                        proc = self._processes[process_id]
                        if proc.stdout:
                            stdout, _ = proc.communicate(timeout=1.0)
                            if stdout:
                                error_output = f"\nProcess output:\n{stdout}"
                except:
                    pass
&gt;               raise ProcessStartupError(f"Process {process_id} died during startup{error_output}")
E               armadillo.core.errors.ProcessStartupError: Process dbserver_3 died during startup

armadillo/core/process.py:509: ProcessStartupError

The above exception was the direct cause of the following exception:

self = &lt;armadillo.instances.server.ArangoServer object at 0x7377a4fd3490&gt;
timeout = 60.0

    def start(self, timeout: Optional[float] = None) -&gt; None:
        """Start the ArangoDB server."""
        if self._is_running:
            raise ServerStartupError(f"Server {self.server_id} is already running")
    
        effective_timeout = clamp_timeout(timeout or 30.0, f"server_start_{self.server_id}")
    
        log_server_event(self._logger, "starting", server_id=self.server_id)
    
        try:
            with timeout_scope(effective_timeout, f"start_server_{self.server_id}"):
                # Build command line
                command = self._build_command()
    
                # Start supervised process from repository root (like old framework)
                repository_root = self._command_builder.get_repository_root()
&gt;               self._process_info = start_supervised_process(
                    self.server_id,
                    command,
                    cwd=repository_root,
                    startup_timeout=effective_timeout,
                    readiness_check=lambda: self._check_readiness(),
                    inherit_console=False  # Capture output to debug startup failures
                )

armadillo/instances/server.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
armadillo/core/process.py:632: in start_supervised_process
    return _process_supervisor.start(process_id, command, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;armadillo.core.process.ProcessSupervisor object at 0x7377a657fd90&gt;
process_id = 'dbserver_3'
command = ['/home/mpoeter/dev/arangodb/arango_next4/build-clang/bin/arangod', '--configuration', 'etc/testing/arangod-dbserver.conf', '--define', 'TOP_DIR=/home/mpoeter/dev/arangodb/arango_next4', '--server.endpoint', ...]
cwd = PosixPath('/home/mpoeter/dev/arangodb/arango_next4'), env = None
startup_timeout = 60.0
readiness_check = &lt;function ArangoServer.start.&lt;locals&gt;.&lt;lambda&gt; at 0x7377a4e89da0&gt;
inherit_console = False

    def start(self,
             process_id: str,
             command: List[str],
             cwd: Optional[Path] = None,
             env: Optional[Dict[str, str]] = None,
             startup_timeout: float = 30.0,
             readiness_check: Optional[Callable[[], bool]] = None,
             inherit_console: bool = False) -&gt; ProcessInfo:
        """Start a supervised process.
    
        Args:
            process_id: Unique identifier for the process
            command: Command and arguments to execute
            cwd: Working directory (optional)
            env: Environment variables (optional)
            startup_timeout: Maximum time to wait for startup (seconds)
            readiness_check: Function to check if process is ready (optional)
            inherit_console: If True, process inherits parent's stdout/stderr directly
                           (no buffering delays). If False, output is captured and
                           streamed with [process_id] prefixes (default: False)
    
        Returns:
            ProcessInfo object with process details
        """
    
        if process_id in self._processes:
            raise ProcessStartupError(f"Process {process_id} is already running")
    
        effective_timeout = clamp_timeout(startup_timeout, f"startup_{process_id}")
    
        log_process_event(logger, "supervisor.start", process_id=process_id,
                         command=command)
    
        # Log complete command line for debugging
        logger.info(f"=== STARTING PROCESS: {process_id} ===")
        logger.info(f"Working directory: {cwd or Path.cwd()}")
        logger.info(f"Complete command line:")
        logger.info(f"  {' '.join(command)}")
        if env:
            logger.info(f"Environment variables: {env}")
        logger.info(f"======================================")
    
        try:
            # Configure stdout/stderr based on inheritance mode
            if inherit_console:
                # Direct console inheritance - no buffering, perfect timing
                stdout_config = None  # Inherit parent's stdout
                stderr_config = None  # Inherit parent's stderr
                use_streaming = False
            else:
                # Captured output with streaming - adds process ID prefixes
                stdout_config = subprocess.PIPE
                stderr_config = subprocess.STDOUT  # Merge stderr into stdout
                use_streaming = True
    
            # Start the process in its own process group for proper cleanup of children
            process = subprocess.Popen(
                command,
                cwd=cwd,
                env=env,
                stdout=stdout_config,
                stderr=stderr_config,
                text=True if use_streaming else None,
                bufsize=1 if use_streaming else -1,  # Line buffered only for streaming
                universal_newlines=True if use_streaming else None,
                start_new_session=True  # Create new process group for proper child cleanup
            )
    
            # Store process information
            process_info = ProcessInfo(
                pid=process.pid,
                command=command,
                start_time=time.time(),
                working_dir=cwd or Path.cwd(),
                env=env or {}
            )
    
            self._processes[process_id] = process
            self._process_info[process_id] = process_info
    
            log_process_event(logger, "supervisor.started",
                            process_id=process_id, pid=process.pid)
    
            # Start output streaming thread (only if not inheriting console)
            if use_streaming:
                self._start_output_streaming(process_id)
    
            # Wait for readiness if check provided
            if readiness_check:
                self._wait_for_readiness(process_id, readiness_check, effective_timeout)
    
            # Start monitoring thread
            self._start_monitoring(process_id)
    
            return process_info
    
        except Exception as e:
            # Try to capture any output from the failed process
            error_output = ""
            try:
                if process_id in self._processes:
                    proc = self._processes[process_id]
                    if proc.stdout:
                        stdout, _ = proc.communicate(timeout=1.0)
                        if stdout:
                            error_output = f"\nProcess output:\n{stdout}"
            except:
                pass
    
            log_process_event(logger, "supervisor.start_failed",
                            process_id=process_id, error=str(e))
            self._cleanup_process(process_id)
&gt;           raise ProcessStartupError(f"Failed to start process {process_id}: {e}{error_output}") from e
E           armadillo.core.errors.ProcessStartupError: Failed to start process dbserver_3: Process dbserver_3 died during startup

armadillo/core/process.py:290: ProcessStartupError

The above exception was the direct cause of the following exception:

self = &lt;armadillo.instances.manager.InstanceManager object at 0x7377a4e21010&gt;

    def _start_cluster(self) -&gt; None:
        """Start cluster deployment in proper sequence: agents -&gt; wait -&gt; dbservers -&gt; coordinators."""
        logger.info("Starting cluster servers in sequence")
    
        # 1. Start agents first
        logger.info("Starting agents...")
        agent_futures = []
        for server_id, server in self._servers.items():
            if server.role == ServerRole.AGENT:
                logger.info(f"Starting agent {server_id}")
                future = self._executor.submit(server.start, 60.0)
                agent_futures.append((server_id, future))
    
        # Wait for all agents to start
        for server_id, future in agent_futures:
            try:
                future.result(timeout=60.0)
                self._startup_order.append(server_id)
                logger.info(f"Agent {server_id} started successfully")
            except Exception as e:
                raise ServerStartupError(f"Failed to start agent {server_id}: {e}")
    
        # 2. Wait for agency to become ready
        logger.info("Waiting for agency to become ready...")
        self._wait_for_agency_ready()
        logger.info("Agency is ready!")
    
        # 3. Start database servers
        logger.info("Starting database servers...")
        dbserver_futures = []
        for server_id, server in self._servers.items():
            if server.role == ServerRole.DBSERVER:
                logger.info(f"Starting database server {server_id}")
                future = self._executor.submit(server.start, 60.0)
                dbserver_futures.append((server_id, future))
    
        # Wait for all database servers to start
        for server_id, future in dbserver_futures:
            try:
&gt;               future.result(timeout=60.0)

armadillo/instances/manager.py:542: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/mpoeter/.local/share/mise/installs/python/3.13.3/lib/python3.13/concurrent/futures/_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
/home/mpoeter/.local/share/mise/installs/python/3.13.3/lib/python3.13/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
/home/mpoeter/.local/share/mise/installs/python/3.13.3/lib/python3.13/concurrent/futures/thread.py:59: in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;armadillo.instances.server.ArangoServer object at 0x7377a4fd3490&gt;
timeout = 60.0

    def start(self, timeout: Optional[float] = None) -&gt; None:
        """Start the ArangoDB server."""
        if self._is_running:
            raise ServerStartupError(f"Server {self.server_id} is already running")
    
        effective_timeout = clamp_timeout(timeout or 30.0, f"server_start_{self.server_id}")
    
        log_server_event(self._logger, "starting", server_id=self.server_id)
    
        try:
            with timeout_scope(effective_timeout, f"start_server_{self.server_id}"):
                # Build command line
                command = self._build_command()
    
                # Start supervised process from repository root (like old framework)
                repository_root = self._command_builder.get_repository_root()
                self._process_info = start_supervised_process(
                    self.server_id,
                    command,
                    cwd=repository_root,
                    startup_timeout=effective_timeout,
                    readiness_check=lambda: self._check_readiness(),
                    inherit_console=False  # Capture output to debug startup failures
                )
    
                self._is_running = True
                log_server_event(self._logger, "started", server_id=self.server_id,
                               pid=self._process_info.pid)
    
        except Exception as e:
            log_server_event(self._logger, "start_failed", server_id=self.server_id, error=str(e))
            # Clean up on failure
            self._cleanup_on_failure()
&gt;           raise ServerStartupError(f"Failed to start server {self.server_id}: {e}") from e
E           armadillo.core.errors.ServerStartupError: Failed to start server dbserver_3: Failed to start process dbserver_3: Process dbserver_3 died during startup

armadillo/instances/server.py:143: ServerStartupError

During handling of the above exception, another exception occurred:

self = &lt;armadillo.instances.manager.InstanceManager object at 0x7377a4e21010&gt;
timeout = 300.0

    def deploy_servers(self, timeout: float = 300.0) -&gt; None:
        """Deploy all servers according to the current plan.
    
        Args:
            timeout: Maximum time to wait for deployment
    
        Raises:
            ServerStartupError: If server deployment fails
            TimeoutError: If deployment times out
        """
        if not self._deployment_plan:
            raise ServerError("No deployment plan created")
    
        if self._is_deployed:
            raise ServerError("Deployment already active")
    
        plan = self._deployment_plan
        timeout = clamp_timeout(timeout, "deployment")
    
        with timeout_scope(timeout, f"deploy_servers_{self.deployment_id}"):
            logger.info(f"Starting deployment of {len(plan.servers)} servers")
            self._startup_time = time.time()
    
            try:
                # Create server instances
                self._create_server_instances()
    
                # Start servers in proper order
                if plan.deployment_mode == DeploymentMode.SINGLE_SERVER:
                    self._start_single_server()
                elif plan.deployment_mode == DeploymentMode.CLUSTER:
&gt;                   self._start_cluster()

armadillo/instances/manager.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;armadillo.instances.manager.InstanceManager object at 0x7377a4e21010&gt;

    def _start_cluster(self) -&gt; None:
        """Start cluster deployment in proper sequence: agents -&gt; wait -&gt; dbservers -&gt; coordinators."""
        logger.info("Starting cluster servers in sequence")
    
        # 1. Start agents first
        logger.info("Starting agents...")
        agent_futures = []
        for server_id, server in self._servers.items():
            if server.role == ServerRole.AGENT:
                logger.info(f"Starting agent {server_id}")
                future = self._executor.submit(server.start, 60.0)
                agent_futures.append((server_id, future))
    
        # Wait for all agents to start
        for server_id, future in agent_futures:
            try:
                future.result(timeout=60.0)
                self._startup_order.append(server_id)
                logger.info(f"Agent {server_id} started successfully")
            except Exception as e:
                raise ServerStartupError(f"Failed to start agent {server_id}: {e}")
    
        # 2. Wait for agency to become ready
        logger.info("Waiting for agency to become ready...")
        self._wait_for_agency_ready()
        logger.info("Agency is ready!")
    
        # 3. Start database servers
        logger.info("Starting database servers...")
        dbserver_futures = []
        for server_id, server in self._servers.items():
            if server.role == ServerRole.DBSERVER:
                logger.info(f"Starting database server {server_id}")
                future = self._executor.submit(server.start, 60.0)
                dbserver_futures.append((server_id, future))
    
        # Wait for all database servers to start
        for server_id, future in dbserver_futures:
            try:
                future.result(timeout=60.0)
                self._startup_order.append(server_id)
                logger.info(f"Database server {server_id} started successfully")
            except Exception as e:
&gt;               raise ServerStartupError(f"Failed to start database server {server_id}: {e}")
E               armadillo.core.errors.ServerStartupError: Failed to start database server dbserver_3: Failed to start server dbserver_3: Failed to start process dbserver_3: Process dbserver_3 died during startup

armadillo/instances/manager.py:546: ServerStartupError

During handling of the above exception, another exception occurred:

fixturedef = &lt;FixtureDef argname='arango_deployment' scope='session' baseid=''&gt;
request = &lt;SubRequest 'arango_deployment' for &lt;Function test_statistics_correct_endpoint&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
&gt;               return (yield)
                        ^^^^^

/home/mpoeter/.local/share/mise/installs/python/3.13.3/lib/python3.13/site-packages/pytest_asyncio/plugin.py:681: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
armadillo/pytest_plugin/plugin.py:319: in arango_deployment
    cluster_manager = _plugin._get_or_create_cluster()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
armadillo/pytest_plugin/plugin.py:348: in _get_or_create_cluster
    manager.deploy_servers(timeout=300.0)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;armadillo.instances.manager.InstanceManager object at 0x7377a4e21010&gt;
timeout = 300.0

    def deploy_servers(self, timeout: float = 300.0) -&gt; None:
        """Deploy all servers according to the current plan.
    
        Args:
            timeout: Maximum time to wait for deployment
    
        Raises:
            ServerStartupError: If server deployment fails
            TimeoutError: If deployment times out
        """
        if not self._deployment_plan:
            raise ServerError("No deployment plan created")
    
        if self._is_deployed:
            raise ServerError("Deployment already active")
    
        plan = self._deployment_plan
        timeout = clamp_timeout(timeout, "deployment")
    
        with timeout_scope(timeout, f"deploy_servers_{self.deployment_id}"):
            logger.info(f"Starting deployment of {len(plan.servers)} servers")
            self._startup_time = time.time()
    
            try:
                # Create server instances
                self._create_server_instances()
    
                # Start servers in proper order
                if plan.deployment_mode == DeploymentMode.SINGLE_SERVER:
                    self._start_single_server()
                elif plan.deployment_mode == DeploymentMode.CLUSTER:
                    self._start_cluster()
    
                # Verify deployment health
                self._verify_deployment_health()
    
                self._is_deployed = True
                self._is_healthy = True
    
                deployment_time = time.time() - self._startup_time
                logger.info(f"Deployment completed successfully in {deployment_time:.2f}s")
    
            except Exception as e:
                logger.error(f"Deployment failed: {e}")
                # Try to cleanup partial deployment
                try:
                    self.shutdown_deployment()
                except:
                    pass
&gt;               raise ServerStartupError(f"Failed to deploy servers: {e}")
E               armadillo.core.errors.ServerStartupError: Failed to deploy servers: Failed to start database server dbserver_3: Failed to start server dbserver_3: Failed to start process dbserver_3: Process dbserver_3 died during startup

armadillo/instances/manager.py:191: ServerStartupError</error></testcase></testsuite></testsuites>